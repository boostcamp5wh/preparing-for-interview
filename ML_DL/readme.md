## 목차
1. [Gradient Descent](./1.Gradient_Descent)
2. [Federated Learning](./2.Federated_Learning)

---
## 질문 후보
1. Cross Validation은 무엇이고 어떻게 해야하나요?
2. 알고 있는 metric에 대해 설명해주세요(ex. RMSE, MAE, recall, precision …)
3. 정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?
4. 최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?
5. Training 세트와 Test 세트를 분리하는 이유는?
    1. Validation 세트가 따로 있는 이유는?
    2. Test 세트가 오염되었다는 말의 뜻은?
    3. Regularization이란 무엇인가?
6. SGD, RMSprop, Adam에 대해서 아는대로 설명한다면?
    1. SGD에서 Stochastic의 의미는?
    2. 미니배치를 작게 할때의 장단점은?
    3. 모멘텀의 수식을 적어 본다면?
7. Batch Normalization의 효과는?
    1. BN 적용해서 학습 이후 실제 사용시에 주의할 점은? 코드로는?

### 밑에는 보이저엑스 면접 질문
8. Dropout의 효과는?
9. Auto Encoder란?
10. CycleGAN이란?
11. Sigmoid의 단점은?
12. Loss Surface란?
13. Attention이란?
14. 중심극한정리란?
15. SVD란?
16. Federated Learning이란?
17. Few-Shot Learning이란?
18. Collaborative filtering이란?
19. Transformer란?
20. Attention이란?
21. ~~Gradient Descent~~
